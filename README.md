Чек лист:
1. Функциональные и нефункциональные требования 
   ### Функциональные требования

   1. Сбор данных о действиях пользователей
      - Система должна регистрировать клики по ключевым элементам интерфейса (фильмы, трейлеры, категории, кнопки навигации).
      
   2. Отслеживание поведения на страницах
      - Серверная система должна фиксировать посещение пользователями конкретных страниц (страницы фильмов, категорий, акции, рекомендации), включая метрики времени пребывания на странице.
      
   3. Поддержка кастомных событий
      - Регистрация смены качества видео — запись перехода между различными разрешениями воспроизведения.
      - Отмечать просмотр видео до конца (фиксирование полного завершения видеоматериала).
      - Сбор данных о применении фильтров поиска, например выбор жанра, рейтинга, актеров.

   ### Нефункциональные требования

   Нагрузка
   - Ежедневная активная аудитория (DAU) составляет примерно 10000 активных пользователей в сутки.
   - Месячная активная аудитория (MAU) достигает примерно 30000 уникальных пользователей ежемесячно.

   Производительность
   - В среднем один пользователь совершает 10 действий в день. Среднее назругка: 1-2 RPS. Пиковую нагрузку примем: 3-6 RPS.

   Размер сообщений
   - Средний объем передаваемых данных одного запроса находится в пределах от 1 Кб до 5 Кб.

   Надёжность
   - Обработка событий должна происходить с минимальным временем отклика (не более 1 секунды на обработку стандартного события).
   - Среднее время восстановления сервиса после сбоя должно составлять менее часа.


2. Задача на отрисовку архитектуры сервиса.
В директории лежит файл схемы спринт UGC.pdf (наставник оценил)

3. API для сбора пользовательских действий, принимающее данные пользователей и отправляющее их в Kafka.
 - Api реализован на flask
 - Добавлена документация api (сделана одна универсальная ручка, документация доступна по адресу localhost:9001/apidocs/)
 - Добавлено ограничения количества запросов в middleware по ip
 (запуск api осуществялется через run_app.sh)


4. Исследование по выбору хранилища, где необходимо сравнить ClickHouse и Vertica.

    ### Сравнение производительности ClickHouse и Vertica при вставке и агрегации большого объёма данных.

      ## Условия тестирования

      - Структура таблицы:

        CREATE TABLE events (
             event_time TIMESTAMP,
             user_id INT,
             event_type VARCHAR(20),
             value FLOAT
         );

      - Объём данных: 10 000 000 записей

      - SQL-запрос для агрегации:

         SELECT event_type, count(), avg(value) FROM events GROUP BY event_type

      - Агрегация выполнялась в 8 потоков

      - Запуск осуществлялся командой: docker compose up из директории test_storage

      ## Результаты

      # Вставка данных (среднее время)

         ClickHouse: 46.64 секунд

         Vertica: 100.43 секунд

      # Агрегация (8 потоков, среднее время)

         ClickHouse: 0.27 секунд

         Vertica: 0.73 секунд


      Использовались официальные docker-образы ClickHouse и Vertica.

      Подключение к БД:

      ClickHouse: через библиотеку clickhouse-driver

      Vertica: через библиотеку vertica_python

      Все скрипты реализованы на Python и размещены в test_storage

      ## Выводы

      - ClickHouse значительно опережает Vertica по скорости массовой вставки и агрегаций в многопоточном режиме.

      - Vertica остаётся стабильной СУБД, но по метрикам реального времени уступает ClickHouse.

      - Для задач real-time аналитики ClickHouse выглядит более предпочтительным решением.

5. ETL-сервис для переноса данных из Kafka в ClickHouse.
ETL сервис запускается вместе с сервисом api. ( run_etl.sh)

Сервис UGC запускается вызовом docker compose up из папки ugc